<!-- Generated by SpecStory -->

# Change code to parse multiple files (2025-09-13 23:26Z)

_**User (2025-09-13 12:50Z)**_

change this code that I can parse all the files instead of specifiy one 

---

_**Assistant**_

<think><details><summary>Thought Process</summary>The user wants to modify the `parse_specstory.py` script to parse all files instead of specifying just one file. Currently, the script takes a single file path as a command-line argument and processes that one file.

Looking at the code:
- The `main()` function currently expects `sys.argv[1]` to be a file path
- It processes one file and saves the output to a `cleaned_data` directory relative to that file

The user likely wants to:
1. Either parse all `.md` files in a directory (or specific pattern)
2. Or parse multiple files at once

I should modify the script to:
1. Accept a directory path (or pattern) instead of just a single file
2. Find all relevant `.md` files (likely `.specstory` files based on the filename pattern)
3. Process each file and save the results

Let me check what files might be relevant by looking at the project structure and git status. From the git status, I can see there are `.specstory/history/` files with `.md` extension.

I'll modify the script to:
1. Accept either a file path or directory path
2. If it's a directory, find all `.md` files in it (and subdirectories)
3. Process each file and save results with the same naming convention</details></think>

---

I'll modify the code to parse all markdown files in a directory instead of just one file. Let me update the script to handle multiple files:

```python:clean_data/parse_specstory.py
#!/usr/bin/env python3
"""
Parser for .specstory markdown files to extract conversations and todo lists.
"""

import re
import json
import os
from typing import Dict, List, Any, Optional
from datetime import datetime
import sys
from pathlib import Path
import glob


class SpecStoryParser:
    def __init__(self, file_path: str):
        self.file_path = file_path
        self.content = self._read_file()

    def _read_file(self) -> str:
        """Read the markdown file content."""
        with open(self.file_path, "r", encoding="utf-8") as f:
            return f.read()

    def parse(self) -> Dict[str, Any]:
        """Parse the entire document and return structured data."""
        data = {
            "file_path": self.file_path,
            "main_timestamp": self._extract_main_timestamp(),
            "title": self._extract_title(),
            "conversations": self._extract_conversations(),
            "all_todo_lists": [],
        }

        # Collect all todo lists from conversations
        for conv in data["conversations"]:
            if conv["type"] == "assistant" and "todo_lists" in conv:
                data["all_todo_lists"].extend(conv["todo_lists"])

        return data

    # ... existing methods remain unchanged ...

    def _extract_todo_lists(self, content: str) -> List[Dict[str, Any]]:
        """Extract all todo lists from content."""
        todo_lists = []

        # Find all todo list sections
        todo_pattern = r"##\s+Todo List\s*\n(.*?)(?=\n---|\n##|\Z)"
        todo_matches = re.finditer(todo_pattern, content, re.DOTALL)

        for match in todo_matches:
            todo_content = match.group(1).strip()
            items = []

            # Parse individual todo items
            item_pattern = r"-\s*\[([ x-])\]\s*(.+?)(?=\n-|\Z)"
            item_matches = re.finditer(item_pattern, todo_content, re.DOTALL)

            for item_match in item_matches:
                status_char = item_match.group(1)
                task = item_match.group(2).strip()

                # Map status characters to status strings
                status_map = {"x": "completed", "-": "in_progress", " ": "pending"}
                status = status_map.get(status_char, "pending")

                items.append({"task": task, "status": status})

            if items:
                todo_lists.append(
                    {
                        "items": items,
                        "total_items": len(items),
                        "completed_items": sum(
                            1 for item in items if item["status"] == "completed"
                        ),
                        "in_progress_items": sum(
                            1 for item in items if item["status"] == "in_progress"
                        ),
                        "pending_items": sum(
                            1 for item in items if item["status"] == "pending"
                        ),
                    }
                )

        return todo_lists


def process_file(file_path: str, output_dir: str) -> Dict[str, Any]:
    """Process a single file and save the results."""
    try:
        parser = SpecStoryParser(file_path)
        data = parser.parse()
        
        # Generate output file path
        base_name = os.path.basename(file_path).replace(".md", "_parsed.json")
        output_file = os.path.join(output_dir, base_name)
        
        # Save to JSON file
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        return {
            "status": "success",
            "file": file_path,
            "output": output_file,
            "conversations": len(data["conversations"]),
            "todo_lists": len(data["all_todo_lists"])
        }
    except Exception as e:
        return {
            "status": "error",
            "file": file_path,
            "error": str(e)
        }


def find_markdown_files(path: str, pattern: str = "*.md") -> List[str]:
    """Find all markdown files in the given path."""
    path_obj = Path(path)
    
    if path_obj.is_file():
        # If it's a single file, return it as a list
        return [str(path_obj)] if path_obj.suffix == ".md" else []
    elif path_obj.is_dir():
        # If it's a directory, find all matching files recursively
        return sorted(glob.glob(str(path_obj / "**" / pattern), recursive=True))
    else:
        # Try as a glob pattern
        return sorted(glob.glob(path, recursive=True))


def main():
    """Main function to run the parser."""
    if len(sys.argv) < 2:
        print("Usage: python parse_specstory.py <path_to_directory_or_file> [pattern]")
        print("Examples:")
        print("  python parse_specstory.py .specstory/history/")
        print("  python parse_specstory.py .specstory/history/ '*.md'")
        print("  python parse_specstory.py path/to/single/file.md")
        sys.exit(1)

    input_path = sys.argv[1]
    pattern = sys.argv[2] if len(sys.argv) > 2 else "*.md"
    
    # Find all markdown files
    files = find_markdown_files(input_path, pattern)
    
    if not files:
        print(f"❌ No markdown files found in: {input_path}")
        sys.exit(1)
    
    print(f"\n=== SpecStory Parser ===")
    print(f"Found {len(files)} file(s) to process")
    
    # Determine output directory
    if Path(input_path).is_file():
        # For single file, create cleaned_data next to the file
        output_dir = os.path.join(os.path.dirname(input_path), "cleaned_data")
    else:
        # For directory, create cleaned_data in current working directory
        output_dir = os.path.join(os.getcwd(), "cleaned_data")
    
    os.makedirs(output_dir, exist_ok=True)
    print(f"Output directory: {output_dir}\n")
    
    # Process all files
    results = []
    for i, file_path in enumerate(files, 1):
        print(f"[{i}/{len(files)}] Processing: {file_path}")
        result = process_file(file_path, output_dir)
        results.append(result)
        
        if result["status"] == "success":
            print(f"  ✅ Success - {result['conversations']} conversations, {result['todo_lists']} todo lists")
            print(f"  📁 Saved to: {result['output']}")
        else:
            print(f"  ❌ Error: {result['error']}")
    
    # Summary
    print(f"\n=== Summary ===")
    successful = sum(1 for r in results if r["status"] == "success")
    failed = sum(1 for r in results if r["status"] == "error")
    
    print(f"Total files processed: {len(files)}")
    print(f"  ✅ Successful: {successful}")
    print(f"  ❌ Failed: {failed}")
    
    if failed > 0:
        print(f"\nFailed files:")
        for r in results:
            if r["status"] == "error":
                print(f"  - {r['file']}: {r['error']}")
    
    # Save summary report
    summary_file = os.path.join(output_dir, "parsing_summary.json")
    with open(summary_file, "w", encoding="utf-8") as f:
        json.dump({
            "timestamp": datetime.now().isoformat(),
            "input_path": input_path,
            "pattern": pattern,
            "total_files": len(files),
            "successful": successful,
            "failed": failed,
            "results": results
        }, f, indent=2)
    
    print(f"\n📊 Summary report saved to: {summary_file}")


if __name__ == "__main__":
    main()
```

The key changes I made:

1. **Added file discovery functionality** - The `find_markdown_files()` function can handle:
   - Single file paths
   - Directory paths (searches recursively for all `.md` files)
   - Glob patterns for more flexibility

2. **Separated file processing** - Created `process_file()` function to handle individual file parsing and saving, making it reusable for multiple files

3. **Enhanced command-line interface**:
   - Can now accept a directory path or file path
   - Optional second argument for file pattern (defaults to `*.md`)
   - Better usage instructions

4. **Progress tracking** - Shows progress as it processes multiple files with success/error status

5. **Summary report** - Creates a `parsing_summary.json` file with details about all processed files

6. **Flexible output directory**:
   - For single files: creates `cleaned_data` next to the file
   - For directories: creates `cleaned_data` in current working directory

Now you can use it in several ways:

---

<think><details><summary>Thought Process</summary>The user wanted to modify the code to parse all files instead of specifying one. I've provided a comprehensive solution that:

1. Maintains backward compatibility (can still process single files)
2. Adds the ability to process entire directories
3. Supports glob patterns for more flexibility
4. Provides clear progress tracking and error reporting
5. Creates a summary report of all processed files

The code is well-structured with separated concerns and proper error handling. This should meet the user's needs perfectly.</details></think>

---

```bash
# Parse all .md files in a directory recursively
python clean_data/parse_specstory.py .specstory/history/

# Parse with a specific pattern
python clean_data/parse_specstory.py . "**/*.specstory.md"

# Still works with single files
python clean_data/parse_specstory.py path/to/single/file.md
```

The script will now:
- Find all markdown files in the specified directory (recursively)
- Process each file individually
- Show progress and results for each file
- Create a summary report with statistics
- Handle errors gracefully without stopping the entire batch

---

